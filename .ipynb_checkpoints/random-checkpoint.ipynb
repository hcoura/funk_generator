{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import sqlite3\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('funk_crawler/songs.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute('SELECT text from songs')\n",
    "songs = cursor.fetchall()\n",
    "text = '\\n'.join([song[0] for song in songs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shave_marks_latin(txt):\n",
    "    norm_text = unicodedata.normalize('NFD', txt)\n",
    "    latin_base = False\n",
    "    keepers = []\n",
    "    for c in norm_text:\n",
    "        if unicodedata.combining(c) and latin_base:\n",
    "            continue\n",
    "        keepers.append(c)\n",
    "        if not unicodedata.combining(c):\n",
    "            latin_base = c in string.ascii_letters\n",
    "    shaved = ''.join(keepers)\n",
    "    return unicodedata.normalize('NFC', shaved)\n",
    "\n",
    "text = shave_marks_latin(text).lower()\n",
    "letter_space_re = re.compile(r'[^a-z\\s]')\n",
    "text = letter_space_re.sub('', text)\n",
    "sentences = text.split('\\n')\n",
    "\n",
    "sentences = set(sentences)\n",
    "\n",
    "tokenizer = re.compile(r'\\s+')\n",
    "sentences_tokens = [tokenizer.split(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_tokens = [sentence for sentence in sentences_tokens\n",
    "                    if len(sentence) < 10][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set([w for s in sentences_tokens for w in s])\n",
    "\n",
    "word_indices = dict((c, i) for i, c in enumerate(words))\n",
    "indices_word = dict((i, c) for i, c in enumerate(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.zeros((len(sentences), 10, len(words)), dtype=np.bool)\n",
    "# y = np.zeros((len(sentences), , len(words)), dtype=np.bool)\n",
    "# for i, sentence in enumerate(sentences_tokens):\n",
    "#     for t, word in enumerate(sentence):\n",
    "#         x[i, t, word_indices[word]] = 1\n",
    "#     y[i, word_indices[next_chars[i]]] = 1\n",
    "    \n",
    "# def data_processing(corpus, values_indices, m = 60, Tx = 30):\n",
    "#     # cut the corpus into semi-redundant sequences of Tx values\n",
    "Tx = 10\n",
    "N_values = len(words)\n",
    "m = len(sentences_tokens)\n",
    "X = np.zeros((m, Tx, N_values), dtype=np.bool)\n",
    "Y = np.zeros((m, Tx, N_values), dtype=np.bool)\n",
    "for i in range(m):\n",
    "    data = sentences_tokens[i]\n",
    "    for j in range(Tx):\n",
    "        try:\n",
    "            idx = word_indices[data[j]]\n",
    "        except IndexError:\n",
    "            idx = word_indices['']\n",
    "        if j != 0:\n",
    "            X[i, j, idx] = 1\n",
    "            Y[i, j-1, idx] = 1\n",
    "\n",
    "Y = np.swapaxes(Y,0,1)\n",
    "# Y = Y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a = 64\n",
    "reshapor = Reshape((1, N_values))\n",
    "LSTM_cell = LSTM(n_a, return_state = True)\n",
    "densor = Dense(N_values, activation='softmax')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funkmodel():\n",
    "    # Define the input of your model with a shape \n",
    "    X = Input(shape=(Tx, N_values))\n",
    "    \n",
    "    # Define s0, initial hidden state for the decoder LSTM\n",
    "    a0 = Input(shape=(n_a,), name='a0')\n",
    "    c0 = Input(shape=(n_a,), name='c0')\n",
    "    a = a0\n",
    "    c = c0\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    # Step 1: Create empty list to append the outputs while you iterate (≈1 line)\n",
    "    outputs = []\n",
    "    \n",
    "    # Step 2: Loop\n",
    "    for t in range(Tx):\n",
    "\n",
    "        # Step 2.A: select the \"t\"th time step vector from X. \n",
    "        x = Lambda(lambda x: X[:,t,:])(X)\n",
    "        # Step 2.B: Use reshapor to reshape x to be (1, n_values) (≈1 line)\n",
    "        x = reshapor(x)\n",
    "        # Step 2.C: Perform one step of the LSTM_cell\n",
    "        a, _, c = LSTM_cell(x, initial_state=[a, c])\n",
    "        # Step 2.D: Apply densor to the hidden state output of LSTM_Cell\n",
    "        out = densor(a)\n",
    "        # Step 2.E: add the output to \"outputs\"\n",
    "        outputs.append(out)\n",
    "        \n",
    "    # Step 3: Create model instance\n",
    "    model = Model(inputs=[X, a0, c0], outputs=outputs)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = funkmodel()\n",
    "\n",
    "opt = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "a0 = np.zeros((m, n_a))\n",
    "c0 = np.zeros((m, n_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 27.0235 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.0000e+00 - dense_2_acc_2: 0.2000 - dense_2_acc_3: 0.2000 - dense_2_acc_4: 0.0000e+00 - dense_2_acc_5: 0.0000e+00 - dense_2_acc_6: 0.0000e+00 - dense_2_acc_7: 0.0000e+00 - dense_2_acc_8: 0.0000e+00 - dense_2_acc_9: 0.0000e+00\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 25.6400 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.2000 - dense_2_acc_2: 0.4000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.0839 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.2000 - dense_2_acc_2: 0.4000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.9522 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.2000 - dense_2_acc_2: 0.4000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.8734 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.2000 - dense_2_acc_2: 0.4000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.5519 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.2000 - dense_2_acc_2: 0.4000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.8462 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.2000 - dense_2_acc_2: 0.4000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.8691 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.2000 - dense_2_acc_2: 0.4000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.3847 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.2000 - dense_2_acc_2: 0.4000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.6021 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.2000 - dense_2_acc_2: 0.4000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.3655 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.2000 - dense_2_acc_2: 0.4000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13.7980 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.2000 - dense_2_acc_2: 0.4000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.0849 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.2000 - dense_2_acc_2: 0.4000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.4062 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.2000 - dense_2_acc_2: 0.4000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.9178 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.2000 - dense_2_acc_2: 0.4000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.7314 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.4000 - dense_2_acc_2: 0.4000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.8114 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.4000 - dense_2_acc_2: 0.6000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 11.8888 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.4000 - dense_2_acc_2: 0.6000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.7805 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.4000 - dense_2_acc_2: 0.6000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.8000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 11.5127 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.4000 - dense_2_acc_2: 0.6000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.8000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 11.1729 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.4000 - dense_2_acc_2: 0.6000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.8474 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.4000 - dense_2_acc_2: 0.6000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.5848 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.4000 - dense_2_acc_2: 0.6000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 10.3904 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.4000 - dense_2_acc_2: 0.6000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10.2418 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.4000 - dense_2_acc_2: 0.6000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.1071 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.4000 - dense_2_acc_2: 0.6000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.9565 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.4000 - dense_2_acc_2: 0.6000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.7705 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.4000 - dense_2_acc_2: 0.6000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.5467 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.4000 - dense_2_acc_2: 0.6000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.3016 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.4000 - dense_2_acc_2: 0.6000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.0664 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.4000 - dense_2_acc_2: 0.8000 - dense_2_acc_3: 0.4000 - dense_2_acc_4: 0.6000 - dense_2_acc_5: 0.6000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.8734 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.4000 - dense_2_acc_2: 0.8000 - dense_2_acc_3: 0.6000 - dense_2_acc_4: 0.8000 - dense_2_acc_5: 0.8000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.7281 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.4000 - dense_2_acc_2: 0.8000 - dense_2_acc_3: 0.6000 - dense_2_acc_4: 0.8000 - dense_2_acc_5: 0.8000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.5790 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.4000 - dense_2_acc_2: 0.8000 - dense_2_acc_3: 0.6000 - dense_2_acc_4: 0.8000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.3710 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.4000 - dense_2_acc_2: 0.8000 - dense_2_acc_3: 0.6000 - dense_2_acc_4: 0.8000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.1287 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.4000 - dense_2_acc_2: 0.8000 - dense_2_acc_3: 0.6000 - dense_2_acc_4: 0.8000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.9158 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.6000 - dense_2_acc_2: 0.8000 - dense_2_acc_3: 0.6000 - dense_2_acc_4: 0.8000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.7497 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.6000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 0.6000 - dense_2_acc_4: 0.8000 - dense_2_acc_5: 0.8000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.5977 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.6000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 0.6000 - dense_2_acc_4: 0.8000 - dense_2_acc_5: 0.8000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.4264 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.6000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 0.8000 - dense_2_acc_4: 0.8000 - dense_2_acc_5: 0.8000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.2275 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.6000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 0.8000 - dense_2_acc_4: 0.8000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.0252 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.8000 - dense_2_acc_2: 0.8000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.8626 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.8000 - dense_2_acc_2: 0.8000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.7402 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.8000 - dense_2_acc_2: 0.8000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.5671 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.8000 - dense_2_acc_2: 0.8000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.3828 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.8000 - dense_2_acc_2: 0.8000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.2478 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.8000 - dense_2_acc_2: 0.8000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.1266 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.8000 - dense_2_acc_2: 0.8000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.9822 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.8000 - dense_2_acc_2: 0.8000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.8283 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.8000 - dense_2_acc_2: 0.8000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7058 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.8000 - dense_2_acc_2: 0.8000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6031 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.8000 - dense_2_acc_2: 0.8000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4533 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.8000 - dense_2_acc_2: 0.8000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.3356 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.8000 - dense_2_acc_2: 0.8000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.2336 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.8000 - dense_2_acc_2: 0.8000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1158 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.8000 - dense_2_acc_2: 0.8000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9927 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.8000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8924 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.8000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7956 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.8000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6818 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.8000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5888 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 0.8000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5005 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.4051 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.3128 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.2326 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.1534 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.0703 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.9970 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9287 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.8600 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.7927 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.7309 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.6741 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.6164 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5609 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.5102 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.4614 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.4132 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.3665 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.3228 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.2813 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.2399 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.2002 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.1628 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.1266 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.0909 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.0567 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.0243 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.9929 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.9620 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9325 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.9043 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.8769 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.8501 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.8244 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.7997 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.7757 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.7523 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.7298 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.7081 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.2000 - dense_2_acc_1: 1.0000 - dense_2_acc_2: 1.0000 - dense_2_acc_3: 1.0000 - dense_2_acc_4: 1.0000 - dense_2_acc_5: 1.0000 - dense_2_acc_6: 1.0000 - dense_2_acc_7: 1.0000 - dense_2_acc_8: 1.0000 - dense_2_acc_9: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7e4e5d0c50>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X, a0, c0], list(Y), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x):\n",
    "    # THIS IS NOT SAMPLING, JUST PICKING THE MOST LIKELY\n",
    "    x = K.argmax(x)\n",
    "    x = tf.one_hot(x, N_values) \n",
    "    x = RepeatVector(1)(x)\n",
    "    return x\n",
    "\n",
    "def inference_model(LSTM_cell, densor, n_values, n_a, Ty = 20):\n",
    "    \"\"\"\n",
    "    Uses the trained \"LSTM_cell\" and \"densor\" from model() to generate a sequence of values.\n",
    "    \n",
    "    Arguments:\n",
    "    LSTM_cell -- the trained \"LSTM_cell\" from model(), Keras layer object\n",
    "    densor -- the trained \"densor\" from model(), Keras layer object\n",
    "    n_values -- integer, umber of unique values\n",
    "    n_a -- number of units in the LSTM_cell\n",
    "    Ty -- integer, number of time steps to generate\n",
    "    \n",
    "    Returns:\n",
    "    inference_model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input of your model with a shape \n",
    "    x0 = Input(shape=(1, n_values))\n",
    "    \n",
    "    # Define s0, initial hidden state for the decoder LSTM\n",
    "    a0 = Input(shape=(n_a,), name='a0')\n",
    "    c0 = Input(shape=(n_a,), name='c0')\n",
    "    a = a0\n",
    "    c = c0\n",
    "    x = x0\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    # Step 1: Create an empty list of \"outputs\" to later store your predicted values (≈1 line)\n",
    "    outputs = []\n",
    "    \n",
    "    # Step 2: Loop over Ty and generate a value at every time step\n",
    "    for t in range(Ty):\n",
    "        print(x)\n",
    "        print(a)\n",
    "        print(c)\n",
    "        # Step 2.A: Perform one step of LSTM_cell (≈1 line)\n",
    "        a, _, c = LSTM_cell(x, initial_state=[a, c])\n",
    "        \n",
    "        # Step 2.B: Apply Dense layer to the hidden state output of the LSTM_cell (≈1 line)\n",
    "        out = densor(a)\n",
    "\n",
    "        # Step 2.C: Append the prediction \"out\" to \"outputs\". out.shape = (None, 78) (≈1 line)\n",
    "        outputs.append(out)\n",
    "        \n",
    "        # Step 2.D: Select the next value according to \"out\", and set \"x\" to be the one-hot representation of the\n",
    "        #           selected value, which will be passed as the input to LSTM_cell on the next step. We have provided \n",
    "        #           the line of code you need to do this. \n",
    "        x = Lambda(one_hot)(out)\n",
    "        \n",
    "    # Step 3: Create model instance with the correct \"inputs\" and \"outputs\" (≈1 line)\n",
    "    inference_model = Model(inputs=[x0, a0, c0], outputs=outputs)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return inference_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_8:0\", shape=(?, 1, 20), dtype=float32)\n",
      "Tensor(\"a0_7:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"c0_7:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lambda_22/repeat_vector_3/Tile:0\", shape=(?, 1, 20), dtype=float32)\n",
      "Tensor(\"lstm_2_10/TensorArrayReadV3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lstm_2_10/while/Exit_3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lambda_23/repeat_vector_5/Tile:0\", shape=(?, 1, 20), dtype=float32)\n",
      "Tensor(\"lstm_2_11/TensorArrayReadV3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lstm_2_11/while/Exit_3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lambda_24/repeat_vector_7/Tile:0\", shape=(?, 1, 20), dtype=float32)\n",
      "Tensor(\"lstm_2_12/TensorArrayReadV3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lstm_2_12/while/Exit_3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lambda_25/repeat_vector_9/Tile:0\", shape=(?, 1, 20), dtype=float32)\n",
      "Tensor(\"lstm_2_13/TensorArrayReadV3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lstm_2_13/while/Exit_3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lambda_26/repeat_vector_11/Tile:0\", shape=(?, 1, 20), dtype=float32)\n",
      "Tensor(\"lstm_2_14/TensorArrayReadV3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lstm_2_14/while/Exit_3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lambda_27/repeat_vector_13/Tile:0\", shape=(?, 1, 20), dtype=float32)\n",
      "Tensor(\"lstm_2_15/TensorArrayReadV3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lstm_2_15/while/Exit_3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lambda_28/repeat_vector_15/Tile:0\", shape=(?, 1, 20), dtype=float32)\n",
      "Tensor(\"lstm_2_16/TensorArrayReadV3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lstm_2_16/while/Exit_3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lambda_29/repeat_vector_17/Tile:0\", shape=(?, 1, 20), dtype=float32)\n",
      "Tensor(\"lstm_2_17/TensorArrayReadV3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lstm_2_17/while/Exit_3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lambda_30/repeat_vector_19/Tile:0\", shape=(?, 1, 20), dtype=float32)\n",
      "Tensor(\"lstm_2_18/TensorArrayReadV3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lstm_2_18/while/Exit_3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lambda_31/repeat_vector_21/Tile:0\", shape=(?, 1, 20), dtype=float32)\n",
      "Tensor(\"lstm_2_19/TensorArrayReadV3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lstm_2_19/while/Exit_3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lambda_32/repeat_vector_23/Tile:0\", shape=(?, 1, 20), dtype=float32)\n",
      "Tensor(\"lstm_2_20/TensorArrayReadV3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lstm_2_20/while/Exit_3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lambda_33/repeat_vector_25/Tile:0\", shape=(?, 1, 20), dtype=float32)\n",
      "Tensor(\"lstm_2_21/TensorArrayReadV3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lstm_2_21/while/Exit_3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lambda_34/repeat_vector_27/Tile:0\", shape=(?, 1, 20), dtype=float32)\n",
      "Tensor(\"lstm_2_22/TensorArrayReadV3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lstm_2_22/while/Exit_3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lambda_35/repeat_vector_29/Tile:0\", shape=(?, 1, 20), dtype=float32)\n",
      "Tensor(\"lstm_2_23/TensorArrayReadV3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lstm_2_23/while/Exit_3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lambda_36/repeat_vector_31/Tile:0\", shape=(?, 1, 20), dtype=float32)\n",
      "Tensor(\"lstm_2_24/TensorArrayReadV3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lstm_2_24/while/Exit_3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lambda_37/repeat_vector_33/Tile:0\", shape=(?, 1, 20), dtype=float32)\n",
      "Tensor(\"lstm_2_25/TensorArrayReadV3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lstm_2_25/while/Exit_3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lambda_38/repeat_vector_35/Tile:0\", shape=(?, 1, 20), dtype=float32)\n",
      "Tensor(\"lstm_2_26/TensorArrayReadV3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lstm_2_26/while/Exit_3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lambda_39/repeat_vector_37/Tile:0\", shape=(?, 1, 20), dtype=float32)\n",
      "Tensor(\"lstm_2_27/TensorArrayReadV3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lstm_2_27/while/Exit_3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lambda_40/repeat_vector_39/Tile:0\", shape=(?, 1, 20), dtype=float32)\n",
      "Tensor(\"lstm_2_28/TensorArrayReadV3:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"lstm_2_28/while/Exit_3:0\", shape=(?, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "inference_model = inference_model(LSTM_cell, densor, n_values = N_values, n_a = n_a, Ty = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_initializer = np.zeros((1, 1, N_values))\n",
    "a_initializer = np.zeros((1, n_a))\n",
    "c_initializer = np.zeros((1, n_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_sample(inference_model, x_initializer = x_initializer, a_initializer = a_initializer, \n",
    "                       c_initializer = c_initializer):\n",
    "    \"\"\"\n",
    "    Predicts the next value of values using the inference model.\n",
    "    \n",
    "    Arguments:\n",
    "    inference_model -- Keras model instance for inference time\n",
    "    x_initializer -- numpy array of shape (1, 1, 78), one-hot vector initializing the values generation\n",
    "    a_initializer -- numpy array of shape (1, n_a), initializing the hidden state of the LSTM_cell\n",
    "    c_initializer -- numpy array of shape (1, n_a), initializing the cell state of the LSTM_cel\n",
    "    \n",
    "    Returns:\n",
    "    results -- numpy-array of shape (Ty, 78), matrix of one-hot vectors representing the values generated\n",
    "    indices -- numpy-array of shape (Ty, 1), matrix of indices representing the values generated\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Step 1: Use your inference model to predict an output sequence given x_initializer, a_initializer and c_initializer.\n",
    "    pred = inference_model.predict([x_initializer, a_initializer, c_initializer])\n",
    "    # Step 2: Convert \"pred\" into an np.array() of indices with the maximum probabilities\n",
    "    indices = np.argmax(pred, axis=-1)\n",
    "    # Step 3: Convert indices to one-hot vectors, the shape of the results should be (1, )\n",
    "    results = to_categorical(indices, num_classes=N_values)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return results, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.argmax(results[12]) = 0\n",
      "np.argmax(results[17]) = 0\n",
      "list(indices[12:18]) = [array([0]), array([0]), array([0]), array([0]), array([0]), array([0])]\n"
     ]
    }
   ],
   "source": [
    "results, indices = predict_and_sample(inference_model, x_initializer, a_initializer, c_initializer)\n",
    "print(\"np.argmax(results[12]) =\", np.argmax(results[12]))\n",
    "print(\"np.argmax(results[17]) =\", np.argmax(results[17]))\n",
    "print(\"list(indices[12:18]) =\", list(indices[12:18]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meu som\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([indices_word[i[0]] for i in indices]).strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
